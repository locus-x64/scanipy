#!/usr/bin/env python3
import os
import sys
import argparse
import subprocess
import tempfile
import shutil
from pathlib import Path
from colorama import init, Fore, Back, Style

# Initialize colorama for cross-platform color support
init(autoreset=True)

# Color and styling utilities
class Colors:
    HEADER = Fore.CYAN + Style.BRIGHT
    SUCCESS = Fore.GREEN + Style.BRIGHT
    WARNING = Fore.YELLOW + Style.BRIGHT
    ERROR = Fore.RED + Style.BRIGHT
    INFO = Fore.BLUE + Style.BRIGHT
    PROGRESS = Fore.CYAN
    REPO_NAME = Fore.MAGENTA + Style.BRIGHT
    STARS = Fore.YELLOW + Style.BRIGHT
    FILES = Fore.GREEN
    URL = Fore.BLUE + Style.DIM
    DESCRIPTION = Fore.WHITE + Style.DIM
    RESET = Style.RESET_ALL

def print_banner():
    """Print a colorful banner for the tool"""
    banner = f"""
{Colors.HEADER}‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                          üì° SCANIPY                          ‚ïë
‚ïë              Code Pattern Scanner for GitHub                 ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù{Colors.RESET}
"""
    print(banner)

def print_search_info(query, language, extension, pages, keywords=None):
    """Print search parameters in a formatted way"""
    print(f"{Colors.INFO}üîç Search Parameters:{Colors.RESET}")
    print(f"   {Colors.INFO}‚Ä¢{Colors.RESET} Query: {Colors.WARNING}'{query}'{Colors.RESET}")
    if language:
        print(f"   {Colors.INFO}‚Ä¢{Colors.RESET} Language: {Colors.SUCCESS}{language}{Colors.RESET}")
    if extension:
        print(f"   {Colors.INFO}‚Ä¢{Colors.RESET} Extension: {Colors.SUCCESS}{extension}{Colors.RESET}")
    if keywords:
        print(f"   {Colors.INFO}‚Ä¢{Colors.RESET} Keywords: {Colors.WARNING}{', '.join(keywords)}{Colors.RESET}")
    print(f"   {Colors.INFO}‚Ä¢{Colors.RESET} Max Pages: {Colors.WARNING}{pages}{Colors.RESET}")
    print()

def format_star_count(stars):
    """Format star count with appropriate color and formatting"""
    if stars == 'N/A':
        return f"{Colors.WARNING}N/A{Colors.RESET}"
    elif stars >= 10000:
        return f"{Colors.SUCCESS}‚≠ê {stars:,}{Colors.RESET}"
    elif stars >= 1000:
        return f"{Colors.STARS}‚≠ê {stars:,}{Colors.RESET}"
    else:
        return f"{Colors.WARNING}‚≠ê {stars}{Colors.RESET}"

def print_repository(index, repo, query):
    """Print a single repository with colorful formatting"""
    # Repository header
    print(f"{Colors.HEADER}{'‚îÄ' * 80}{Colors.RESET}")
    print(f"{Colors.INFO}{index:2d}.{Colors.RESET} {Colors.REPO_NAME}{repo['name']}{Colors.RESET} {format_star_count(repo.get('stars', 'N/A'))}")
    
    # Description
    if repo.get('description'):
        desc = repo['description']
        if len(desc) > 100:
            desc = desc[:97] + "..."
        print(f"    {Colors.DESCRIPTION}üìù {desc}{Colors.RESET}")
    
    # File count
    file_count = len(repo['files'])
    if file_count > 0:
        print(f"    {Colors.FILES}üìÅ {file_count} file{'s' if file_count != 1 else ''} containing '{query}'{Colors.RESET}")
        
        # Show files with keyword information
        for i, file in enumerate(repo['files'][:3]):
            file_line = f"    {Colors.FILES}‚îú‚îÄ{Colors.RESET} {file['path']}"
            
            # Add keyword match information
            if file.get('keyword_match') is True:
                keywords_str = ', '.join(file.get('keywords_found', []))
                file_line += f" {Colors.SUCCESS}[Keywords: {keywords_str}]{Colors.RESET}"
            elif file.get('keyword_match') is False:
                file_line += f" {Colors.WARNING}[No keywords found]{Colors.RESET}"
            elif file.get('keyword_match') is None:
                file_line += f" {Colors.WARNING}[Content unavailable]{Colors.RESET}"
            
            print(file_line)
        
        if len(repo['files']) > 3:
            remaining = len(repo['files']) - 3
            print(f"    {Colors.FILES}‚îî‚îÄ{Colors.RESET} {Colors.WARNING}... and {remaining} more file{'s' if remaining != 1 else ''}{Colors.RESET}")
    
    # URL
    if repo.get('url'):
        print(f"    {Colors.URL}üîó {repo['url']}{Colors.RESET}")
    
    print()

def setup_argparser():
    parser = argparse.ArgumentParser(
    description='Search for open source repositories containing specific code patterns and sort by stars.',
    formatter_class=argparse.RawDescriptionHelpFormatter,
    epilog='''
Examples:

    # Search for a pattern
    scanipy --query "extractall"
    
    # Search for a specific language
    scanipy --query "pickle.loads" --language python
  
    # Search with keyword filtering
    scanipy --query "extractall" --keywords "path,directory,zip" --language python
  
    # Search with a higher page limit 
    scanipy --query "pickle.loads" --pages 10
  
    # Search in specific file types
    scanipy --query "os.system" --language python --extension ".py"
  
    # Search with additional filters
    scanipy --query "subprocess.call" --additional-params "stars:>100"
    
    # Run semrep on top repositories
    scanipy --query "extractall" --run-semrep
    '''
    )

    # Search query parameters
    parser.add_argument(
        '--query', '-q',
        required=True,
        help='Code pattern to search for (e.g., "extractall")'
    )
    parser.add_argument(
        '--language', '-l',
        default='',
        help='Programming language to search in (e.g., python)'
    )
    parser.add_argument(
        '--extension', '-e',
        default='',
        help='File extension to search in (e.g., ".py", ".ipynb")'
    )
    parser.add_argument(
        '--keywords', '-k',
        default='',
        help='Comma-separated keywords to look for in files containing the main pattern (e.g., "path,directory,zip")'
    )
    parser.add_argument(
        '--additional-params',
        default='',
        help='Additional search parameters (e.g., "stars:>100 -org:microsoft")'
    )
    # Pagination and limits
    parser.add_argument(
        '--pages', '-p',
        type=int,
        default=5,
        help='Maximum number of pages to retrieve (default: 5, max 10 pages = 1000 results)'
    )
    # GitHub API authentication
    parser.add_argument(
        '--github-token',
        help='GitHub personal access token (also can be set via GITHUB_TOKEN env variable)'
    )
    # Output options
    parser.add_argument(
        '--output', '-o',
        default='repos.json',
        help='Output JSON file path (default: repos.json)'
    )
    parser.add_argument(
        '--verbose', '-v',
        action='store_true',
        help='Enable verbose output'
    )
    # New semrep options
    parser.add_argument(
        '--run-semrep',
        action='store_true',
        help='Run semrep analysis on the top 10 repositories'
    )
    parser.add_argument(
        '--semrep-args',
        default='',
        help='Additional arguments to pass to semrep (e.g., "--json --verbose"). Quote the arguments as a single string.'
    )
    parser.add_argument(
        '--pro',
        action='store_true',
        help='Use semgrep with the --pro flag'
    )
    parser.add_argument(
        '--rules',
        default=None,
        help='Path to custom semgrep rules file or directory (YAML format)'
    )
    parser.add_argument(
        '--clone-dir',
        default=None,
        help='Directory to clone repositories into (default: temporary directory)'
    )
    parser.add_argument(
        '--keep-cloned',
        action='store_true',
        help='Keep cloned repositories after analysis (only applicable with --clone-dir)'
    )
    
    args = parser.parse_args()
    
    # Parse keywords
    if args.keywords:
        args.keywords_list = [kw.strip() for kw in args.keywords.split(',') if kw.strip()]
    else:
        args.keywords_list = []
    
    # Build the complete search query
    query_parts = []
    if args.query:
        query_parts.append(args.query)
    if args.language:
        query_parts.append(f"language:{args.language}")
    if args.extension:
        query_parts.append(f"extension:{args.extension}")
    if args.additional_params:
        query_parts.append(args.additional_params)
    args.full_query = " ".join(query_parts)
    
    return args

def check_command_exists(cmd):
    """Check if a command exists in the system PATH"""
    try:
        subprocess.run(['which', cmd], check=True, capture_output=True)
        return True
    except subprocess.CalledProcessError:
        return False

def clone_repository(repo_url, clone_path):
    """Clone a GitHub repository to the specified path"""
    try:
        subprocess.run(['git', 'clone', '--depth=1', repo_url, clone_path], check=True, capture_output=True)
        return True
    except subprocess.CalledProcessError as e:
        print(f"{Colors.ERROR}‚ùå Failed to clone {repo_url}: {e}{Colors.RESET}")
        return False

def run_semrep_analysis(repo_path, semrep_args='', rules_path=None, use_pro=False):
    """Run semrep analysis on a repository"""
    try:
        # Use semgrep scan instead of just semgrep
        cmd = ['semgrep', 'scan']
        
        # Add pro flag if enabled
        if use_pro:
            cmd.append('--pro')
        
        # Add custom rules file if provided
        if rules_path:
            # Check if rules file exists
            if not os.path.exists(rules_path):
                return False, f"Error: Rules file or directory not found: {rules_path}"
            cmd.extend(['--config', rules_path])
        
        # Add any additional arguments
        if semrep_args and semrep_args.strip():
            cmd.extend(semrep_args.split())
            
        # Add target directory to scan
        cmd.append(repo_path)
        
        print(f"{Colors.INFO}üîç Running semgrep: {' '.join(cmd)}{Colors.RESET}")
        result = subprocess.run(cmd, check=True, capture_output=True, text=True)
        return True, result.stdout
    except subprocess.CalledProcessError as e:
        return False, f"Error running semgrep: {e}\nOutput: {e.stdout}\nError: {e.stderr}"

def analyze_repositories_with_semrep(repo_list, semrep_args='', clone_dir=None, keep_cloned=False, rules_path=None, use_pro=False):
    """Clone and analyze repositories with semrep"""
    if not check_command_exists('semgrep'):
        print(f"{Colors.ERROR}‚ùå Error: semgrep is not installed on your system.{Colors.RESET}")
        print(f"{Colors.INFO}üí° To install semgrep, follow instructions at https://github.com/semgrep/semgrep{Colors.RESET}")
        return
    
    if not check_command_exists('git'):
        print(f"{Colors.ERROR}‚ùå Error: git is not installed on your system.{Colors.RESET}")
        return
    
    # Create temp directory if clone_dir is not specified
    using_temp_dir = clone_dir is None
    if using_temp_dir:
        clone_dir = tempfile.mkdtemp(prefix="scanipy_repos_")
        print(f"{Colors.INFO}üìÅ Created temporary directory for cloning: {clone_dir}{Colors.RESET}")
    else:
        # Make sure the directory exists
        os.makedirs(clone_dir, exist_ok=True)
        print(f"{Colors.INFO}üìÅ Using directory for cloning: {clone_dir}{Colors.RESET}")
    
    # Take only the first 10 repositories to analyze
    repos_to_analyze = repo_list[:10] if len(repo_list) > 10 else repo_list
    
    print(f"{Colors.HEADER}{'‚îÄ' * 80}{Colors.RESET}")
    print(f"{Colors.INFO}üöÄ Running semgrep analysis on the top {len(repos_to_analyze)} repositories...{Colors.RESET}")
    if rules_path:
        print(f"{Colors.INFO}üìù Using custom rules from: {rules_path}{Colors.RESET}")
    if use_pro:
        print(f"{Colors.INFO}üîí Using semgrep with --pro flag{Colors.RESET}")
    print(f"{Colors.HEADER}{'‚îÄ' * 80}{Colors.RESET}")
    
    results = []
    
    for i, repo in enumerate(repos_to_analyze):
        repo_url = repo.get('url')
        if not repo_url:
            continue
            
        repo_name = repo.get('name', f"repo_{i}")
        clone_path = os.path.join(clone_dir, repo_name.replace("/", "_"))
        
        print(f"\n{Colors.INFO}[{i+1}/{len(repos_to_analyze)}] Analyzing {Colors.REPO_NAME}{repo_name}{Colors.RESET}")
        
        # Clone the repository
        print(f"{Colors.PROGRESS}üì• Cloning repository: {repo_url} to {clone_path}...{Colors.RESET}")
        if clone_repository(repo_url, clone_path):
            print(f"{Colors.SUCCESS}‚úÖ Cloning successful{Colors.RESET}")
            
            # Run semgrep
            print(f"{Colors.PROGRESS}üîç Running semgrep analysis...{Colors.RESET}")
            success, output = run_semrep_analysis(clone_path, semrep_args, rules_path=rules_path, use_pro=use_pro)
            
            if success:
                print(f"{Colors.SUCCESS}‚úÖ semgrep analysis complete{Colors.RESET}")
                print(f"\n{Colors.HEADER}--- semgrep results for {repo_name} ---{Colors.RESET}")
                print(output)
                print(f"{Colors.HEADER}{'‚îÄ' * 80}{Colors.RESET}")
                
                results.append({
                    "repo": repo_name,
                    "success": True,
                    "output": output
                })
            else:
                print(f"{Colors.ERROR}‚ùå semgrep analysis failed{Colors.RESET}")
                print(f"{Colors.ERROR}{output}{Colors.RESET}")
                
                results.append({
                    "repo": repo_name,
                    "success": False,
                    "output": output
                })
        else:
            results.append({
                "repo": repo_name,
                "success": False,
                "output": "Failed to clone repository"
            })
    
    # Clean up if using a temporary directory and not keeping clones
    if using_temp_dir and not keep_cloned:
        print(f"{Colors.INFO}üßπ Cleaning up temporary directory...{Colors.RESET}")
        try:
            shutil.rmtree(clone_dir)
            print(f"{Colors.SUCCESS}‚úÖ Cleanup successful{Colors.RESET}")
        except Exception as e:
            print(f"{Colors.ERROR}‚ùå Failed to clean up: {e}{Colors.RESET}")
    elif keep_cloned:
        print(f"{Colors.INFO}üíæ Repositories have been kept at: {clone_dir}{Colors.RESET}")
    
    # Summary
    print(f"\n{Colors.HEADER}{'‚îÄ' * 80}{Colors.RESET}")
    print(f"{Colors.INFO}üìä semrep Analysis Summary:{Colors.RESET}")
    print(f"{Colors.INFO}‚úì Successfully analyzed: {sum(1 for r in results if r['success'])}/{len(results)} repositories{Colors.RESET}")
    print(f"{Colors.INFO}‚úó Failed to analyze: {sum(1 for r in results if not r['success'])}/{len(results)} repositories{Colors.RESET}")
    print(f"{Colors.HEADER}{'‚îÄ' * 80}{Colors.RESET}")
    
    return results

if __name__ == "__main__":
    args = setup_argparser()
    
    # Check if GITHUB_TOKEN is set in environment variables
    if not args.github_token:
        args.github_token = os.getenv("GITHUB_TOKEN")
    
    if not args.github_token:
        print(f"{Colors.ERROR}‚ùå Error: GITHUB_TOKEN environment variable or --github-token argument must be set.{Colors.RESET}")
        sys.exit(1)
    
    print_banner()
    
    # Print search information
    print_search_info(args.query, args.language, args.extension, args.pages, args.keywords_list)
    
    # Initialize GitHub API client
    from github import RestAPI as GHRest
    from github import GraphQLAPI as GHGraphQL
    ghrest = GHRest(token=args.github_token)
    ghrest.search(args.query, language=args.language, extension=args.extension, per_page=100, max_pages=args.pages, additional_params=args.additional_params)
    repos = ghrest.repositories
    
    # Apply keyword filtering if keywords are provided
    if args.keywords_list:
        ghrest.filter_by_keywords(args.keywords_list)
        repos = ghrest.repositories
    
    ghgraphql = GHGraphQL(token=args.github_token, repositories=repos)
    ghgraphql.batch_query()
    
    repos = ghgraphql.repositories
    
    repo_list = list(repos.values())
    repo_list.sort(key=lambda x: x.get("stars", 0), reverse=True)
    
    # Print top repositories
    if repo_list:
        print(f"{Colors.SUCCESS}üéØ TOP REPOSITORIES BY STARS:{Colors.RESET}")
        for i, repo in enumerate(repo_list[:20], 1):
            print_repository(i, repo, args.query)
        
        # Run semrep on top repositories if requested
        if args.run_semrep:
            analyze_repositories_with_semrep(
                repo_list, 
                semrep_args=args.semrep_args,
                clone_dir=args.clone_dir,
                keep_cloned=args.keep_cloned,
                rules_path=args.rules,
                use_pro=args.pro
            )
    else:
        print(f"{Colors.WARNING}üì≠ No repositories found matching your criteria.{Colors.RESET}")
        if args.keywords_list:
            print(f"{Colors.INFO}üí° Try with fewer or different keywords, or search without keyword filtering.{Colors.RESET}")

